{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the following 3 cells to create a list of features, create a train/test split, and instantiate a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIMIT_BAL',\n",
       " 'EDUCATION',\n",
       " 'MARRIAGE',\n",
       " 'AGE',\n",
       " 'PAY_1',\n",
       " 'BILL_AMT1',\n",
       " 'BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'PAY_AMT1',\n",
       " 'PAY_AMT2',\n",
       " 'PAY_AMT3',\n",
       " 'PAY_AMT4',\n",
       " 'PAY_AMT5',\n",
       " 'PAY_AMT6',\n",
       " 'default payment next month']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_response = df.columns.tolist()\n",
    "items_to_remove = ['ID', 'SEX', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "                   'EDUCATION_CAT', 'graduate school', 'high school', 'none',\n",
    "                   'others', 'university']\n",
    "features_response = [item for item in features_response if item not in items_to_remove]\n",
    "features_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features_response[:-1]].values,\n",
    "    df['default payment next month'].values,\n",
    "    test_size=0.2, random_state=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=10, criterion='gini', max_depth=3,\n",
    "    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None,\n",
    "    random_state=4, verbose=0, warm_start=False, class_weight=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dictionary representing the grid for the max_depth and n_estimators hyperparameters that will be searched. Include depths of 3, 6, 9, and 12, and 10, 50, 100, and 200 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':[ 3, 6, 9,12],\n",
    "         'n_estimators':[10, 50, 100,200]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate a GridSearchCV object using the same options that we have previously in this course, but with the dictionary of hyperparameters created above. Set verbose=2 to see the output for each fit performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cv = GridSearchCV(rf, param_grid=params, scoring='roc_auc',\n",
    "                  n_jobs=None, iid=False, refit=True, cv=4, verbose=2,\n",
    "                  pre_dispatch=None, error_score=np.nan, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit the GridSearchCV object on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=50, total=   0.4s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=50, total=   0.4s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=50, total=   0.4s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=50, total=   0.4s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   0.9s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   0.9s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   0.9s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   0.9s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=200, total=   1.7s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=200, total=   1.7s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=200, total=   2.1s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=200, total=   1.7s\n",
      "[CV] max_depth=6, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=6, n_estimators=10, total=   0.2s\n",
      "[CV] max_depth=6, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=6, n_estimators=10, total=   0.2s\n",
      "[CV] max_depth=6, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=6, n_estimators=10, total=   0.2s\n",
      "[CV] max_depth=6, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=6, n_estimators=10, total=   0.2s\n",
      "[CV] max_depth=6, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=6, n_estimators=50, total=   0.7s\n",
      "[CV] max_depth=6, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=6, n_estimators=50, total=   0.8s\n",
      "[CV] max_depth=6, n_estimators=50 ....................................\n"
     ]
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put the results of the grid search in a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(cv.cv_results_)\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a pcolormesh visualization of the mean testing score for each combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 5x5 grid\n",
    "x_1, y_1 = np.meshgrid(range(5), range(5))\n",
    "print(x_1)\n",
    "print(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mean_test = cv_results_df[\"mean_test_score\"].values.reshape(4,4)\n",
    "cv_mean_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color map to `plt.cm.jet`\n",
    "ax = plt.axes()\n",
    "pcolor_ex = ax.pcolormesh(x_1, y_1, cv_mean_test, cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pcolormesh\n",
    "ax = plt.axes()\n",
    "pcolor_ex = ax.pcolormesh(x_1, y_1, cv_mean_test, cmap=plt.cm.jet)\n",
    "plt.colorbar(pcolor_ex, label='Color scale')\n",
    "ax.set_xlabel('X coordinate')\n",
    "ax.set_ylabel('Y coordinate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the feature names and importance\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature name':features_response[:-1],\n",
    "    'Importance':cv.best_estimator_.feature_importances_\n",
    "})\n",
    "# Sort values by importance\n",
    "feat_imp_df.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
